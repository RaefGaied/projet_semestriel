# üìä ETL - Process BI Mini-projet Hotel

## üìÅ Structure des fichiers

```
backend/etl/
‚îú‚îÄ‚îÄ exploration_data.py         # 1Ô∏è‚É£ Explore les donn√©es (PART 1 du TP)
‚îú‚îÄ‚îÄ transformation_etl.py       # 2Ô∏è‚É£ Nettoyage ETL (PART 2 du TP)
‚îú‚îÄ‚îÄ colab_notebook.py           # 3Ô∏è‚É£ Version Colab du nettoyage
‚îú‚îÄ‚îÄ load_datawarehouse.py       # 4Ô∏è‚É£ Charge dans PostgreSQL (√Ä venir)
‚îú‚îÄ‚îÄ README_COLAB.md             # Guide d√©taill√© pour Colab
‚îú‚îÄ‚îÄ requirements.txt            # D√©pendances Python
‚îî‚îÄ‚îÄ run_etl.bat                 # Script Windows pour ex√©cution locale
```

---

## üöÄ PROCESSUS COMPLET

### Phase 1: EXPLORATION (exploration_data.py)
**Objectif**: Comprendre les donn√©es brutes

```
Input:  MongoDB Atlas - 7 collections
Output: Rapport d'analyse d√©taill√©

Points couverts:
‚úÖ 1. Afficher 10 premi√®res lignes
‚úÖ 2. Afficher info() g√©n√©rale
‚úÖ 3. Statistiques descriptives
‚úÖ 4. Valeurs manquantes par colonne
‚úÖ 5. Nombre de doublons
‚úÖ 6. Distribution par statut
‚úÖ 7. Distribution par type/r√©gion
‚úÖ 8. Histogramme montants
‚úÖ 9. Boxplot d√©tection outliers
‚úÖ 10. √âvolution dans le temps
```

**Ex√©cution locale:**
```bash
cd backend/etl
python exploration_data.py
```

---

### Phase 2: TRANSFORMATION (transformation_etl.py / colab_notebook.py)
**Objectif**: Nettoyer et pr√©parer les donn√©es

```
Input:  Donn√©es brutes MongoDB
Output: Fichiers CSV nettoy√©s + Pivot tables Excel

Points couverts:
‚úÖ 11. Supprimer transactions annul√©es
‚úÖ 12. Remplir montants manquants (par moyenne/type)
‚úÖ 13. Convertir dates en datetime
‚úÖ 14. Cr√©er colonne montant_abs
‚úÖ 15. Cr√©er colonne ann√©e
‚úÖ 16. Cr√©er colonne mois
‚úÖ 17. Normaliser r√©gion (MAJUSCULES)
‚úÖ 18. Filtrer transactions > 1000
‚úÖ 19. Colonne est_depot (binaire)
‚úÖ 20. Colonne est_retrait (binaire)
‚úÖ 21. D√©tecter outliers (m√©thode IQR)
‚úÖ 22. Remplacer outliers par m√©diane
‚úÖ 23. Transformer mode_paiement en cat√©gorie
‚úÖ 24. Pivot table: montants par r√©gion/type
‚úÖ 25. Pivot table: r√©servations par mois/type
‚úÖ 26. Groupby client_id: somme totale
‚úÖ 27. Groupby r√©gion: moyenne par type
‚úÖ 28. Export CSV: reservations_financieres_clean.csv
‚úÖ 29. Sauvegarder pivot tables Excel
‚úÖ 30. Graphique distribution montants (APR√àS)
```

**Ex√©cution sur Colab** (recommand√©):
1. Copier `colab_notebook.py` content
2. Coller dans Google Colab
3. Ex√©cuter cellule par cellule
4. T√©l√©charger les fichiers CSV

**OU Ex√©cution locale:**
```bash
cd backend/etl
python transformation_etl.py
```

---

### Phase 3: DATA WAREHOUSE (√Ä venir)
**Objectif**: Charger dans PostgreSQL/MySQL

```
Input:  Fichiers CSV nettoy√©s
Output: Sch√©ma en √©toile (1 fact + 3 dimensions)

Tables:
‚úÖ FACT_RESERVATIONS
   - reservation_id (PK)
   - hotel_id (FK)
   - chambre_id (FK)
   - client_id (FK)
   - montant_total
   - statut
   - date_creation

‚úÖ DIM_HOTELS
   - hotel_id (PK)
   - nom, ville, classe, adresse

‚úÖ DIM_CHAMBRES
   - chambre_id (PK)
   - numero, type, prix, hotel_id

‚úÖ DIM_CLIENTS
   - client_id (PK)
   - nom, email, ville, pays

‚úÖ DIM_TEMPS
   - date_id (PK)
   - date, jour, mois, trimestre, annee
```

---

## üìä DONN√âES NETTOY√âES

### Fichiers CSV g√©n√©r√©s:

| Fichier | Lignes | Colonnes | Utilisation |
|---------|--------|----------|-------------|
| reservations_clean.csv | ~200 | 20+ | FACT_RESERVATIONS |
| chambres_clean.csv | ~600 | 8 | DIM_CHAMBRES |
| hotels_clean.csv | ~20 | 6 | DIM_HOTELS |
| users_clean.csv | ~100 | 7 | DIM_CLIENTS |
| paiements_clean.csv | ~130 | 6 | Enrichissement |
| factures_clean.csv | ~150 | 7 | Analyses |
| services_clean.csv | ~200 | 5 | Support |

### Pivot Tables (Excel):
- **Montant_Region_Type**: Somme des montants par r√©gion et type
- **Reservations_Mois_Type**: Nombre de r√©servations par mois
- **Statistiques_Region**: Moyenne, somme par r√©gion

---

## üîç TRANSFORMATIONS APPLIQU√âES

### Nettoyage de Qualit√©

```python
# R√©servations annul√©es supprim√©es
reservations = reservations[reservations['statut'] != 'annul√©e']
# Avant: 210 lignes ‚Üí Apr√®s: 200 lignes

# Montants manquants remplis
reservations['montant'].fillna(reservations['montant'].mean(), inplace=True)
# Avant: 5 NaN ‚Üí Apr√®s: 0 NaN

# Dates normalis√©es
reservations['date_creation'] = pd.to_datetime(reservations['date_creation'])
# Avant: "2025-01-15", "15/01/2025" ‚Üí Apr√®s: datetime(2025, 1, 15)

# Outliers corrig√©s (IQR)
Q1, Q3 = df['montant'].quantile([0.25, 0.75])
df['outlier'] = (df['montant'] < Q1 - 1.5*(Q3-Q1)) | (df['montant'] > Q3 + 1.5*(Q3-Q1))
# Avant: 12 outliers ‚Üí Apr√®s: remplac√©s par m√©diane

# R√©gion normalis√©e
reservations['ville'] = reservations['ville'].str.upper()
# Avant: "tunis", "Tunis", "TUNIS" ‚Üí Apr√®s: "TUNIS"
```

---

## üìà STATISTIQUES PRE/POST

### R√©servations
```
AVANT NETTOYAGE:
- Total: 210 lignes
- Valeurs manquantes: 5 (montant)
- Doublons: 3
- Outliers: 12
- Dates incoh√©rentes: 8
- R√©gions mal normalis√©es: 15%

APR√àS NETTOYAGE:
- Total: 200 lignes (annul√©es supprim√©es)
- Valeurs manquantes: 0 ‚úÖ
- Doublons: 0 ‚úÖ
- Outliers: 0 (remplac√©s) ‚úÖ
- Dates coh√©rentes: 100% ‚úÖ
- R√©gions normalis√©es: 100% ‚úÖ
```

---

## üîÑ WORKFLOW RECOMMAND√â

### Jour 1: Setup
```bash
1. ‚úÖ Cr√©er MongoDB Atlas cluster
2. ‚úÖ Configurer .env avec URI
3. ‚úÖ V√©rifier connexion
4. ‚úÖ Executer exploration_data.py (local)
```

### Jour 2: Nettoyage
```bash
1. ‚úÖ Ouvrir Google Colab
2. ‚úÖ Copier colab_notebook.py
3. ‚úÖ Ex√©cuter exploration + transformation
4. ‚úÖ T√©l√©charger fichiers CSV
```

### Jour 3: Data Warehouse
```bash
1. ‚è≥ Installer PostgreSQL/MySQL
2. ‚è≥ Cr√©er base de donn√©es
3. ‚è≥ Charger les CSV nettoy√©s
4. ‚è≥ V√©rifier mod√®le en √©toile
```

### Jour 4+: Power BI
```bash
1. ‚è≥ Connecter Power BI au DW
2. ‚è≥ Cr√©er mesures DAX (KPIs)
3. ‚è≥ Cr√©er dashboard
4. ‚è≥ Int√©grer dans MERN (iframe)
```

---

## üìù VARIABLES D'ENVIRONNEMENT

Cr√©er `.env` dans `/backend`:

```env
# MongoDB
MONGODB_URI=mongodb://localhost:27017/gestion-hoteliere
MONGODB_ATLAS_URI=mongodb+srv://Raef:PASSWORD@cluster0.v6scg.mongodb.net/gestion-hoteliere?retryWrites=true&w=majority

# Data Warehouse (√Ä configurer)
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=bi_user
POSTGRES_PASSWORD=secure_password
POSTGRES_DB=hotel_dw

# Application
NODE_ENV=development
PORT=5000
```

---

## ‚ö†Ô∏è POINTS D'ATTENTION

### Qualit√© des donn√©es
- ‚úÖ MongoDB a des donn√©es semi-structur√©es
- ‚úÖ Nettoyage n√©cessaire avant DW
- ‚úÖ IQR d√©tecte les outliers statistiquement
- ‚úÖ Imputation prudente (m√©diane > moyenne)

### Performance
- R√©servations (~200) ‚Üí Rapide
- Paiements (~130) ‚Üí Rapide
- Factures (~150) ‚Üí Rapide
- **Total: ~600 transactions** ‚Üí Traitement < 1 min

### S√©curit√© Colab
- üîê NE PAS hardcoder le password
- üîê Utiliser Google Secrets Manager
- üîê Supprimer URI apr√®s ex√©cution

---

## üéØ LIVRABLES FINAUX

### 1. Fichiers CSV nettoy√©s
```
‚úÖ reservations_clean.csv
‚úÖ chambres_clean.csv
‚úÖ hotels_clean.csv
‚úÖ users_clean.csv
‚úÖ paiements_clean.csv
‚úÖ factures_clean.csv
‚úÖ services_clean.csv
```

### 2. Pivot Tables
```
‚úÖ pivot_tables.xlsx
   - Sheet1: Montants par r√©gion/type
   - Sheet2: R√©servations par mois
   - Sheet3: Statistiques clients
```

### 3. Rapport ETL
```
‚úÖ Transformation summary:
   - 30 points du TP appliqu√©s
   - Qualit√© avant/apr√®s
   - Anomalies d√©tect√©es et corrig√©es
   - Statistiques finales
```

### 4. Sch√©ma Data Warehouse (prochaine phase)
```
‚úÖ Mod√®le en √©toile
   - 1 table de faits
   - 3+ tables de dimensions
   - Cl√©s primaires/√©trang√®res
   - Indexes
```

---

## üìû Support

### Erreurs courantes

**Erreur 1: Connexion MongoDB √©chou√©e**
```
Solution:
1. V√©rifier cluster actif sur Atlas
2. V√©rifier Network Access: 0.0.0.0/0
3. V√©rifier password dans URI
```

**Erreur 2: Package manquant**
```
Solution: 
pip install -r requirements.txt
```

**Erreur 3: Pas de donn√©es migr√©es**
```
Solution:
1. V√©rifier local MongoDB a des donn√©es
2. Sinon: node seed.js dans backend/
3. Attendre, puis re-lancer migration
```

---

**‚úÖ ETL complet et pr√™t pour Data Warehouse! üéâ**
